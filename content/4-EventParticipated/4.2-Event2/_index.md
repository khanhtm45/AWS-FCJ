---
title: "Event 2"
date: "2025-10-01"
weight: 1
chapter: false
pre: " <b> 4.2. </b> "
---

# Summary Report: “AI-powered planning, design, and coding for modern software development”

**Overview:** An **on-demand webinar** from **AWS Marketplace** focused on bringing **Generative AI** into **planning – design – coding** across the SDLC to accelerate collaboration, automate testing, generate docs/diagrams, and enforce security via a **zero-trust** approach. (Source: AWS Marketplace webinar page – *On-demand*).

---

### Event Objectives
- Explain how **GenAI** reshapes **planning, design, and coding** on AWS.  
- Show how to integrate GenAI into **Agile/Scrum**: sprint planning, backlog refinement, **test generation**.  
- Demonstrate creating **UI/UX mock-ups**, **architecture diagrams**, and technical docs with AI for faster alignment.  
- Share **security/zero-trust** practices for **code analysis** and **architecture reviews**.

---

### Speakers
- **Harrison Kirby** — Ambassador, **DevOps Institute**  
- **Ronak Shah** — **Principal Solutions Architect**, **AWS**

---

### Highlights
#### 1) GenAI across the SDLC
- **Planning & Design:** AI proposes architecture options and generates **diagrams/docs**; supports early decision-making.  
- **Coding & Testing:** **Real-time code suggestions**, **unit/integration test** generation, fewer fix-rework cycles.  
- **Collaboration:** Rapid **UI/UX mock-ups** to align architects, developers, and designers.

#### 2) “Attendees will learn” (from the webinar page)
- Embedding GenAI into **Agile workflows** for **sprint planning, backlog refinement, test generation**.  
- Using **AI-generated visuals/diagrams/code** to accelerate cross-functional collaboration.  
- Applying **security frameworks** and **zero-trust principles** with AI for **architecture reviews** and **code analysis**.

#### 3) Practical tie-ins (from your supporting document)
- **Governance Copilot:** flags **scope creep/budget drift**; auto-creates **minutes** and **risk registers**.  
- **Smarter Estimation:** learns from historical projects; outputs **best/worst-case** ranges, not a single point.  
- **Scope Clarifier:** NLP capture/analysis to detect **ambiguous/conflicting/missing** requirements before scope lock.  
- **Dependency Radar:** AI-graph mapping of **team/vendor/module** dependencies to avoid bottlenecks.  
- **Auto-documentation:** keeps **UML/sequence/workflow/API docs** in sync with code/design changes.

---

### Key Takeaways
- **Vision → Value:** anchor every GenAI effort to clear **KPIs/ROI** (speed, cost, quality).  
- **Data-first:** **retrieval/embedding/rerank** quality drives output quality.  
- **Security-by-design:** **zero-trust**, access control, PII protection, **content moderation**, **cost/token** visibility.  
- **Observability & Eval:** tracing, online/offline evaluation, continuous **feedback loops**.

---

### Applying to Work
- Pilot 1–2 **GenAI use cases** over 6–8 weeks with **go/no-go gates** (quality, latency, cost/interaction, adoption).  
- Enable a **governance copilot** (scope/budget alerts) and **auto-documentation** from the first sprint.  
- Standardize **estimations** with historical data; publish **2–3 scenarios** instead of one number.  
- Use a **scope clarifier** for all requirement sessions; run a **dependency radar** before major design milestones.

---

### Event Experience
The webinar shows how to **operationalize AI**—from documentation/architecture to code/test and security—helping teams reduce process friction and shorten lead time while maintaining safety and scalability on AWS.

#### Some event photos
*Add your screenshots/photos here*

> In short, the session outlines **measurable GenAI steps** across the SDLC: AI does the heavy lifting, while **humans supervise and decide**.
